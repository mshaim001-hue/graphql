#!/usr/bin/env python3
"""
–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã public.object
–ê–Ω–∞–ª–∏–∑ —Ç–∏–ø–æ–≤ –æ–±—ä–µ–∫—Ç–æ–≤, –∞—Ç—Ä–∏–±—É—Ç–æ–≤ –∏ —Å–≤—è–∑–µ–π
"""

import requests
import json
import os
from collections import defaultdict, Counter

def load_token():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç JWT —Ç–æ–∫–µ–Ω –∏–∑ .env —Ñ–∞–π–ª–∞"""
    try:
        with open('.env', 'r') as f:
            for line in f:
                if line.startswith('GRAPHQL_TOKEN='):
                    return line.split('=', 1)[1].strip().strip('"')
    except FileNotFoundError:
        print("–§–∞–π–ª .env –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return None

def analyze_object_types():
    """–ê–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ –æ–±—ä–µ–∫—Ç–æ–≤ –≤ —Å–∏—Å—Ç–µ–º–µ"""
    token = load_token()
    if not token:
        return
    
    headers = {
        'Authorization': f'Bearer {token}',
        'Content-Type': 'application/json'
    }
    
    # –ó–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ –æ–±—ä–µ–∫—Ç–æ–≤
    query = """
    query {
        object(limit: 1000) {
            id
            name
            type
            attrs
            createdAt
            campus
            authorId
        }
    }
    """
    
    print(f"\n{'='*80}")
    print(f"üîç –ê–ù–ê–õ–ò–ó –¢–ò–ü–û–í –û–ë–™–ï–ö–¢–û–í")
    print(f"{'='*80}")
    
    response = requests.post(
        'https://01.tomorrow-school.ai/api/graphql-engine/v1/graphql',
        json={'query': query},
        headers=headers
    )
    
    if response.status_code == 200:
        data = response.json()
        if 'errors' in data:
            print("‚ùå –û—à–∏–±–∫–∏ GraphQL:")
            for error in data['errors']:
                print(f"   - {error['message']}")
        else:
            objects = data['data']['object']
            print(f"‚úÖ –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {len(objects)} –æ–±—ä–µ–∫—Ç–æ–≤")
            
            # –ê–Ω–∞–ª–∏–∑ –ø–æ —Ç–∏–ø–∞–º
            type_stats = defaultdict(list)
            campus_stats = defaultdict(int)
            author_stats = defaultdict(int)
            attrs_stats = defaultdict(int)
            
            for obj in objects:
                obj_type = obj.get('type', 'unknown')
                campus = obj.get('campus', 'None')
                author_id = obj.get('authorId', 'None')
                attrs = obj.get('attrs', {})
                
                type_stats[obj_type].append(obj)
                campus_stats[campus] += 1
                author_stats[author_id] += 1
                
                # –ê–Ω–∞–ª–∏–∑ –∞—Ç—Ä–∏–±—É—Ç–æ–≤
                if attrs:
                    for key in attrs.keys():
                        attrs_stats[key] += 1
            
            # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ç–∏–ø–∞–º
            print(f"\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –¢–ò–ü–ê–ú –û–ë–™–ï–ö–¢–û–í:")
            print(f"{'–¢–∏–ø':<25} {'–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ':<12} {'–ü—Ä–æ—Ü–µ–Ω—Ç':<10}")
            print("-" * 50)
            
            total_objects = len(objects)
            for obj_type, type_objects in sorted(type_stats.items(), key=lambda x: len(x[1]), reverse=True):
                count = len(type_objects)
                percentage = (count / total_objects) * 100
                print(f"{obj_type:<25} {count:<12} {percentage:.1f}%")
            
            # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∫–∞–º–ø—É—Å–∞–º
            print(f"\nüè´ –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –ö–ê–ú–ü–£–°–ê–ú:")
            for campus, count in sorted(campus_stats.items(), key=lambda x: x[1], reverse=True):
                percentage = (count / total_objects) * 100
                print(f"  {campus}: {count} –æ–±—ä–µ–∫—Ç–æ–≤ ({percentage:.1f}%)")
            
            # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∞–≤—Ç–æ—Ä–∞–º
            print(f"\nüë• –¢–û–ü-10 –ê–í–¢–û–†–û–í:")
            for author_id, count in sorted(author_stats.items(), key=lambda x: x[1], reverse=True)[:10]:
                percentage = (count / total_objects) * 100
                print(f"  Author {author_id}: {count} –æ–±—ä–µ–∫—Ç–æ–≤ ({percentage:.1f}%)")
            
            # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∞—Ç—Ä–∏–±—É—Ç–∞–º
            print(f"\nüè∑Ô∏è –¢–û–ü-15 –ê–¢–†–ò–ë–£–¢–û–í:")
            for attr, count in sorted(attrs_stats.items(), key=lambda x: x[1], reverse=True)[:15]:
                percentage = (count / total_objects) * 100
                print(f"  {attr}: {count} –æ–±—ä–µ–∫—Ç–æ–≤ ({percentage:.1f}%)")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            filename = f"object_analysis_{len(objects)}_items.json"
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(objects, f, indent=2, ensure_ascii=False)
            
            print(f"\nüìÅ –ü–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª: {filename}")
            
            return type_stats, campus_stats, author_stats, attrs_stats
    else:
        print(f"‚ùå HTTP –æ—à–∏–±–∫–∞: {response.status_code}")
        return None, None, None, None

def analyze_specific_type(object_type, type_stats):
    """–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ç–∏–ø–∞ –æ–±—ä–µ–∫—Ç–æ–≤"""
    if not type_stats or object_type not in type_stats:
        print(f"‚ùå –¢–∏–ø '{object_type}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –¥–∞–Ω–Ω—ã—Ö")
        return
    
    objects = type_stats[object_type]
    print(f"\n{'='*80}")
    print(f"üîç –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –¢–ò–ü–ê: {object_type.upper()}")
    print(f"{'='*80}")
    print(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(objects)} –æ–±—ä–µ–∫—Ç–æ–≤ —Ç–∏–ø–∞ '{object_type}'")
    
    # –ê–Ω–∞–ª–∏–∑ –∞—Ç—Ä–∏–±—É—Ç–æ–≤ –¥–ª—è —ç—Ç–æ–≥–æ —Ç–∏–ø–∞
    attrs_analysis = defaultdict(list)
    campus_analysis = defaultdict(int)
    
    for obj in objects:
        attrs = obj.get('attrs', {})
        campus = obj.get('campus', 'None')
        
        campus_analysis[campus] += 1
        
        for key, value in attrs.items():
            attrs_analysis[key].append(value)
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞–º–ø—É—Å–∞–º
    print(f"\nüè´ –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞–º–ø—É—Å–∞–º:")
    for campus, count in sorted(campus_analysis.items(), key=lambda x: x[1], reverse=True):
        percentage = (count / len(objects)) * 100
        print(f"  {campus}: {count} –æ–±—ä–µ–∫—Ç–æ–≤ ({percentage:.1f}%)")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∞—Ç—Ä–∏–±—É—Ç—ã
    print(f"\nüè∑Ô∏è –ê—Ç—Ä–∏–±—É—Ç—ã –¥–ª—è —Ç–∏–ø–∞ '{object_type}':")
    for attr, values in sorted(attrs_analysis.items()):
        unique_values = len(set(str(v) for v in values))
        print(f"  {attr}: {len(values)} –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–π, {unique_values} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –∑–Ω–∞—á–µ–Ω–∏–π
        if unique_values <= 5:
            print(f"    –ü—Ä–∏–º–µ—Ä—ã: {list(set(str(v) for v in values))}")
        else:
            sample_values = list(set(str(v) for v in values))[:3]
            print(f"    –ü—Ä–∏–º–µ—Ä—ã: {sample_values}...")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –æ–±—ä–µ–∫—Ç–æ–≤
    print(f"\nüìã –ü—Ä–∏–º–µ—Ä—ã –æ–±—ä–µ–∫—Ç–æ–≤ —Ç–∏–ø–∞ '{object_type}':")
    for i, obj in enumerate(objects[:5], 1):
        print(f"\n  {i}. {obj.get('name', 'N/A')} (ID: {obj.get('id', 'N/A')})")
        print(f"     Campus: {obj.get('campus', 'N/A')}")
        print(f"     Author: {obj.get('authorId', 'N/A')}")
        print(f"     Created: {obj.get('createdAt', 'N/A')}")
        
        attrs = obj.get('attrs', {})
        if attrs:
            print(f"     Attrs: {list(attrs.keys())}")

def analyze_attrs_structure():
    """–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∞—Ç—Ä–∏–±—É—Ç–æ–≤"""
    token = load_token()
    if not token:
        return
    
    headers = {
        'Authorization': f'Bearer {token}',
        'Content-Type': 'application/json'
    }
    
    # –ó–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –æ–±—ä–µ–∫—Ç–æ–≤ —Å –∞—Ç—Ä–∏–±—É—Ç–∞–º–∏
    query = """
    query {
        object(where: {attrs: {_is_null: false}}, limit: 200) {
            id
            name
            type
            attrs
            campus
        }
    }
    """
    
    print(f"\n{'='*80}")
    print(f"üîç –ê–ù–ê–õ–ò–ó –°–¢–†–£–ö–¢–£–†–´ –ê–¢–†–ò–ë–£–¢–û–í")
    print(f"{'='*80}")
    
    response = requests.post(
        'https://01.tomorrow-school.ai/api/graphql-engine/v1/graphql',
        json={'query': query},
        headers=headers
    )
    
    if response.status_code == 200:
        data = response.json()
        if 'errors' in data:
            print("‚ùå –û—à–∏–±–∫–∏ GraphQL:")
            for error in data['errors']:
                print(f"   - {error['message']}")
        else:
            objects = data['data']['object']
            print(f"‚úÖ –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {len(objects)} –æ–±—ä–µ–∫—Ç–æ–≤ —Å –∞—Ç—Ä–∏–±—É—Ç–∞–º–∏")
            
            # –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∞—Ç—Ä–∏–±—É—Ç–æ–≤
            attr_types = defaultdict(list)
            attr_combinations = defaultdict(int)
            
            for obj in objects:
                attrs = obj.get('attrs', {})
                obj_type = obj.get('type', 'unknown')
                
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–∏–ø—ã –∑–Ω–∞—á–µ–Ω–∏–π –∞—Ç—Ä–∏–±—É—Ç–æ–≤
                for key, value in attrs.items():
                    value_type = type(value).__name__
                    attr_types[key].append(value_type)
                
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ –∞—Ç—Ä–∏–±—É—Ç–æ–≤
                attr_keys = tuple(sorted(attrs.keys()))
                attr_combinations[attr_keys] += 1
            
            # –í—ã–≤–æ–¥–∏–º —Ç–∏–ø—ã –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∞—Ç—Ä–∏–±—É—Ç–∞
            print(f"\nüè∑Ô∏è –¢–ò–ü–´ –ó–ù–ê–ß–ï–ù–ò–ô –ê–¢–†–ò–ë–£–¢–û–í:")
            for attr, types in sorted(attr_types.items()):
                type_counts = Counter(types)
                total = len(types)
                print(f"\n  {attr}:")
                for value_type, count in type_counts.most_common():
                    percentage = (count / total) * 100
                    print(f"    {value_type}: {count} ({percentage:.1f}%)")
            
            # –í—ã–≤–æ–¥–∏–º –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ –∞—Ç—Ä–∏–±—É—Ç–æ–≤
            print(f"\nüîó –ü–û–ü–£–õ–Ø–†–ù–´–ï –ö–û–ú–ë–ò–ù–ê–¶–ò–ò –ê–¢–†–ò–ë–£–¢–û–í:")
            for combo, count in sorted(attr_combinations.items(), key=lambda x: x[1], reverse=True)[:10]:
                if len(combo) > 1:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ –∏–∑ 2+ –∞—Ç—Ä–∏–±—É—Ç–æ–≤
                    print(f"  {combo}: {count} –æ–±—ä–µ–∫—Ç–æ–≤")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
            filename = f"object_attrs_analysis_{len(objects)}_items.json"
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(objects, f, indent=2, ensure_ascii=False)
            
            print(f"\nüìÅ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª: {filename}")
    else:
        print(f"‚ùå HTTP –æ—à–∏–±–∫–∞: {response.status_code}")

def search_objects_by_criteria():
    """–ü–æ–∏—Å–∫ –æ–±—ä–µ–∫—Ç–æ–≤ –ø–æ —Ä–∞–∑–ª–∏—á–Ω—ã–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º"""
    token = load_token()
    if not token:
        return
    
    headers = {
        'Authorization': f'Bearer {token}',
        'Content-Type': 'application/json'
    }
    
    # –†–∞–∑–ª–∏—á–Ω—ã–µ –ø–æ–∏—Å–∫–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã
    search_queries = [
        {
            'name': '–û–±—ä–µ–∫—Ç—ã —Å —è–∑—ã–∫–∞–º–∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è',
            'query': """
            query {
                object(where: {attrs: {language: {_is_null: false}}}, limit: 50) {
                    id
                    name
                    type
                    attrs
                    campus
                }
            }
            """
        },
        {
            'name': '–ü—Ä–æ–µ–∫—Ç—ã —Å –≥—Ä—É–ø–ø–æ–≤–æ–π —Ä–∞–±–æ—Ç–æ–π',
            'query': """
            query {
                object(where: {type: {_eq: "project"}, attrs: {groupMax: {_is_null: false}}}, limit: 30) {
                    id
                    name
                    type
                    attrs
                    campus
                }
            }
            """
        },
        {
            'name': '–û–±—ä–µ–∫—Ç—ã —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π',
            'query': """
            query {
                object(where: {attrs: {validations: {_is_null: false}}}, limit: 30) {
                    id
                    name
                    type
                    attrs
                    campus
                }
            }
            """
        }
    ]
    
    print(f"\n{'='*80}")
    print(f"üîç –ü–û–ò–°–ö –û–ë–™–ï–ö–¢–û–í –ü–û –ö–†–ò–¢–ï–†–ò–Ø–ú")
    print(f"{'='*80}")
    
    for search in search_queries:
        print(f"\nüîç {search['name']}:")
        
        response = requests.post(
            'https://01.tomorrow-school.ai/api/graphql-engine/v1/graphql',
            json={'query': search['query']},
            headers=headers
        )
        
        if response.status_code == 200:
            data = response.json()
            if 'errors' in data:
                print("‚ùå –û—à–∏–±–∫–∏ GraphQL:")
                for error in data['errors']:
                    print(f"   - {error['message']}")
            else:
                objects = data['data']['object']
                print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(objects)} –æ–±—ä–µ–∫—Ç–æ–≤")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã
                for i, obj in enumerate(objects[:3], 1):
                    print(f"  {i}. {obj.get('name', 'N/A')} ({obj.get('type', 'N/A')})")
                    attrs = obj.get('attrs', {})
                    if 'language' in attrs:
                        print(f"     Language: {attrs['language']}")
                    if 'groupMax' in attrs:
                        print(f"     Group: {attrs.get('groupMin', '?')}-{attrs['groupMax']}")
                    if 'validations' in attrs:
                        print(f"     Validations: {len(attrs['validations'])}")
                
                if len(objects) > 3:
                    print(f"  ... –∏ –µ—â–µ {len(objects) - 3} –æ–±—ä–µ–∫—Ç–æ–≤")
        else:
            print(f"‚ùå HTTP –æ—à–∏–±–∫–∞: {response.status_code}")

if __name__ == "__main__":
    print("üöÄ –ó–∞–ø—É—Å–∫ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ public.object")
    
    # –û—Å–Ω–æ–≤–Ω–æ–π –∞–Ω–∞–ª–∏–∑
    type_stats, campus_stats, author_stats, attrs_stats = analyze_object_types()
    
    if type_stats:
        # –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö —Ç–∏–ø–æ–≤
        popular_types = sorted(type_stats.keys(), key=lambda x: len(type_stats[x]), reverse=True)[:5]
        
        for obj_type in popular_types:
            analyze_specific_type(obj_type, type_stats)
    
    # –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∞—Ç—Ä–∏–±—É—Ç–æ–≤
    analyze_attrs_structure()
    
    # –ü–æ–∏—Å–∫ –ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—è–º
    search_objects_by_criteria()
    
    print(f"\n{'='*80}")
    print("‚úÖ –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")
    print(f"{'='*80}")